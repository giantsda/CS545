{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Convolutional-Neural-Networks\" data-toc-modified-id=\"Convolutional-Neural-Networks-1\">Convolutional Neural Networks</a></span><ul class=\"toc-item\"><li><span><a href=\"#Requirements\" data-toc-modified-id=\"Requirements-1.1\">Requirements</a></span></li></ul></li><li><span><a href=\"#Experiments\" data-toc-modified-id=\"Experiments-2\">Experiments</a></span></li><li><span><a href=\"#Grading\" data-toc-modified-id=\"Grading-3\">Grading</a></span></li><li><span><a href=\"#Extra-Credit\" data-toc-modified-id=\"Extra-Credit-4\">Extra Credit</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "\n",
    "For this assignment, use the `NeuralNetworkClassifier_CNN` class defined for you in `neuralnetworks_A4.py` contained in [A4code.tar](https://www.cs.colostate.edu/~anderson/cs545/notebooks/A4code.tar).  This tar file also includes other functions you will use here, contained in `mlfuncs.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T23:41:20.815440Z",
     "start_time": "2021-10-15T23:41:20.802779Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T23:41:21.563150Z",
     "start_time": "2021-10-15T23:41:21.349591Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import neuralnetworks_A4 as nn\n",
    "import mlfuncs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, look carefully at the `neuralnetworks_A4.py` and `optimizers.py` code provided above.  Some changes have been made in each. The most significant change is that the `train` function now accepts a `batch_size` argument so that the gradients we calculate don't have to be over the whole training set.  Recall that we can easily run out of memory with convolutional networks if we calculate gradients over the whole training set.  Also, `'scg'` is not a valid optimizer in this version of the code.\n",
    "\n",
    "Implement the following functions:\n",
    "\n",
    "    dataframe_result = run_these_parameters(X, T, n_folds,\n",
    "                                            layers_structs, \n",
    "                                            methods, \n",
    "                                            epochs, \n",
    "                                            learning_rates.\n",
    "                                            batch_sizes)\n",
    "                                              \n",
    "    result = train_this_partition(Xtrain, Ttrain, Xval, Tval, Xtest, Ttest,\n",
    "                                  struct,\n",
    "                                  n_epochs, \n",
    "                                  method, \n",
    "                                  learning_rate,\n",
    "                                  batch_size)\n",
    "                                  \n",
    "The file `mlfuncs.py` contains several functions you will need to define these two required functions.  They are illustrated in the following examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T23:41:22.456416Z",
     "start_time": "2021-10-15T23:41:22.440139Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60.0"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = np.array([0, 1, 1, 0, 0]).reshape(-1, 1)\n",
    "T = np.array([0, 1, 0, 1, 0]).reshape(-1, 1)\n",
    "mlfuncs.percent_equal(Y, T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of that one is obvious.  This next one is needed for storing your network stucture in a pandas DataFrame.  The structure must be an immutable data type.  A list is mutable, but a tuple is not.  So we must make sure all parts of the network structure specification is composed of tuples, not lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T23:41:23.819633Z",
     "start_time": "2021-10-15T23:41:23.811752Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((), (10,))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct = [ [], [10]]\n",
    "mlfuncs.list_to_tuple(struct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T23:41:24.071779Z",
     "start_time": "2021-10-15T23:41:24.047492Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((2, 4, 1), (5, 4, 2)), (20, 10))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct = [ [[2, 4, 1], [5, 4, 2]], [20, 10]]\n",
    "mlfuncs.list_to_tuple(struct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is a function that generates all training, validation, and testing partitions given the data and the number of folds.  It creates the partitions in a stratified manner, meaning all folds will have close to the same proportion of samples from each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T23:41:24.546767Z",
     "start_time": "2021-10-15T23:41:24.537570Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0,  1],\n",
       "        [ 2,  3],\n",
       "        [ 4,  5],\n",
       "        [ 6,  7],\n",
       "        [ 8,  9],\n",
       "        [10, 11]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1]]))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.arange(12).reshape(6, 2)\n",
    "T = np.array([0, 0, 1, 0, 1, 1]).reshape(-1, 1)\n",
    "X, T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T23:41:25.607634Z",
     "start_time": "2021-10-15T23:41:25.592463Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 7]\n",
      " [4 5]] \n",
      " [[0]\n",
      " [1]] \n",
      " [[0 1]\n",
      " [8 9]] \n",
      " [[0]\n",
      " [1]] \n",
      " [[ 2  3]\n",
      " [10 11]] \n",
      " [[0]\n",
      " [1]]\n",
      "\n",
      "[[0 1]\n",
      " [8 9]] \n",
      " [[0]\n",
      " [1]] \n",
      " [[6 7]\n",
      " [4 5]] \n",
      " [[0]\n",
      " [1]] \n",
      " [[ 2  3]\n",
      " [10 11]] \n",
      " [[0]\n",
      " [1]]\n",
      "\n",
      "[[6 7]\n",
      " [4 5]] \n",
      " [[0]\n",
      " [1]] \n",
      " [[ 2  3]\n",
      " [10 11]] \n",
      " [[0]\n",
      " [1]] \n",
      " [[0 1]\n",
      " [8 9]] \n",
      " [[0]\n",
      " [1]]\n",
      "\n",
      "[[ 2  3]\n",
      " [10 11]] \n",
      " [[0]\n",
      " [1]] \n",
      " [[6 7]\n",
      " [4 5]] \n",
      " [[0]\n",
      " [1]] \n",
      " [[0 1]\n",
      " [8 9]] \n",
      " [[0]\n",
      " [1]]\n",
      "\n",
      "[[0 1]\n",
      " [8 9]] \n",
      " [[0]\n",
      " [1]] \n",
      " [[ 2  3]\n",
      " [10 11]] \n",
      " [[0]\n",
      " [1]] \n",
      " [[6 7]\n",
      " [4 5]] \n",
      " [[0]\n",
      " [1]]\n",
      "\n",
      "[[ 2  3]\n",
      " [10 11]] \n",
      " [[0]\n",
      " [1]] \n",
      " [[0 1]\n",
      " [8 9]] \n",
      " [[0]\n",
      " [1]] \n",
      " [[6 7]\n",
      " [4 5]] \n",
      " [[0]\n",
      " [1]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for Xtrain, Ttrain, Xval, Tval, Xtest, Ttest in mlfuncs.generate_partitions(X, T, n_folds=3, classification=True):\n",
    "        print(Xtrain, '\\n', Ttrain, '\\n', Xval, '\\n', Tval, '\\n', Xtest, '\\n', Ttest)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `run_these_parameters` loops through all values in `layers_structs`, `methods`, `epochs`, `learning rates` and `batch_sizes`.  For each set of parameter values, it loops through all ways of creating training, validation, and testing partitions using `n_folds`.  For each of these repetitions, `train_this_partition` is called to create the specified convolutional neural network, trains it, collects the percent correct on training, validation, and test sets, and returns a list of parameter values and the three accuracies.  `run_these_parameters` returns all of these results as a `pandas` DataFrame with column names `('struct', 'method', 'n_epochs', 'learning_rate', 'batch_size', 'train %', 'val %', 'test %')`. \n",
    "\n",
    "The resulting DataFrame results stored in variable `df` can be summarized with a statement like\n",
    "\n",
    "      df.groupby(['struct', 'method', 'n_epochs', 'learning_rate',\n",
    "                  'batch_size']).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the two required functions in code cells above this cell.\n",
    "\n",
    "The following examples show examples of how they should run, as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T23:41:31.175012Z",
     "start_time": "2021-10-15T23:41:30.389530Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 40 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def make_images(n_each_class):\n",
    "    '''Make 20x20 black and white images with diamonds or squares for the two classes, as line drawings.'''\n",
    "    images = np.zeros((n_each_class * 4, 20, 20))  # nSamples, rows, columns\n",
    "    radii = 3 + np.random.randint(10 - 5, size=(n_each_class * 4, 1))\n",
    "    centers = np.zeros((n_each_class * 4, 2))\n",
    "    for i in range(n_each_class * 4):\n",
    "        r = radii[i, 0]\n",
    "        centers[i, :] = r + 1 + np.random.randint(18 - 2 * r, size=(1, 2))\n",
    "        x = int(centers[i, 0])\n",
    "        y = int(centers[i, 1])\n",
    "        if i < n_each_class:\n",
    "            # plus\n",
    "            images[i, x - r:x + r, y] = 1.0\n",
    "            images[i, x, y - r:y + r] = 1.0\n",
    "        elif i < n_each_class * 2:\n",
    "            # minus\n",
    "            images[i, x, y - r:y + r] = 1.0\n",
    "        elif i < n_each_class * 3:\n",
    "            # x\n",
    "            images[i, range(x - r, x + r), range(y - r, y + r)] = 1.0\n",
    "            images[i, range(x - r, x + r), range(y + r, y - r, -1)] = 1.0\n",
    "        else:\n",
    "            # /\n",
    "            images[i, range(x - r, x + r), range(y - r, y + r)] = 1.0\n",
    "\n",
    "    T = np.array(['plus'] * n_each_class + ['minus'] * n_each_class + ['times'] * n_each_class + ['divide'] * n_each_class).reshape(-1, 1)\n",
    "\n",
    "    n, r, c = images.shape\n",
    "    images = images.reshape(n, r, c, 1)  # add channel dimsension\n",
    "    return images, T\n",
    "\n",
    "n_each_class = 10\n",
    "X, T = make_images(n_each_class)\n",
    "p = 0\n",
    "for i in range(4 * n_each_class):\n",
    "    p += 1\n",
    "    plt.subplot(4, n_each_class, p)\n",
    "    plt.imshow(-X[i, :, :, 0], cmap='gray')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T23:41:32.073364Z",
     "start_time": "2021-10-15T23:41:32.019274Z"
    }
   },
   "outputs": [],
   "source": [
    "n_each_class = 500\n",
    "X, T = make_images(n_each_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T23:41:35.853124Z",
     "start_time": "2021-10-15T23:41:35.643931Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# from A4mysolution import *\n",
    "def train_this_partition(Xtrain, Ttrain, Xval, Tval, Xtest, Ttest, struct, n_epochs, method, learning_rate, batch_size):\n",
    "    mlfuncs.make_batches(Xtrain, Ttrain, batch_size)\n",
    "    nnet_cnn = nn.NeuralNetworkClassifier_CNN([Xtrain.shape[1], Xtrain.shape[2], Xtrain.shape[3]], struct[0], struct[1], np.unique(Ttrain))\n",
    "    nnet_cnn.train(Xtrain, Ttrain, n_epochs, method=method, learning_rate=learning_rate, momentum=0.1, batch_size=batch_size, verbose=False)\n",
    "    \n",
    "    Yval,Y = nnet_cnn.use(Xval)\n",
    "    Ytest,Y = nnet_cnn.use(Xtest)\n",
    "    Ytrain,Y = nnet_cnn.use(Xtrain)\n",
    "    \n",
    "    percentageTrain = mlfuncs.percent_equal(Ytrain, Ttrain)\n",
    "    percentageVal= mlfuncs.percent_equal(Yval, Tval)\n",
    "    percentageTest = mlfuncs.percent_equal(Ytest, Ttest)\n",
    "    Restult = []\n",
    "#   ('struct', 'method', 'n_epochs', 'learning_rate', 'batch_size', 'train %', 'val %', 'test %').\n",
    "\n",
    "\n",
    "    Restult.append(mlfuncs.list_to_tuple(struct))\n",
    "    Restult.append(mlfuncs.list_to_tuple(method))\n",
    "    Restult.append(mlfuncs.list_to_tuple(n_epochs))\n",
    "    Restult.append(mlfuncs.list_to_tuple(learning_rate))\n",
    "    Restult.append(mlfuncs.list_to_tuple(batch_size))\n",
    "    Restult.append(mlfuncs.list_to_tuple(percentageTrain))\n",
    "    Restult.append(mlfuncs.list_to_tuple(percentageVal))\n",
    "    Restult.append(mlfuncs.list_to_tuple(percentageTest))\n",
    " \n",
    "    return Restult\n",
    "\n",
    "\n",
    "\n",
    "def run_these_parameters(X, T, n_folds,\n",
    "            structs, \n",
    "            methods, \n",
    "            epochs, \n",
    "            learning_rates,\n",
    "            batch_sizes):\n",
    "    classes = ['struct', 'method', 'n_epochs', 'learning_rate', 'batch_size', 'train %', 'val %', 'test %']\n",
    "    resultData = []\n",
    "    for struct in structs:\n",
    "        for method in methods:\n",
    "            for epoch in epochs:\n",
    "                for learning_rate in learning_rates:\n",
    "                    for batch_size in batch_sizes:\n",
    "#                           +struct, method, epoch, learning_rate, Xtest, batch_size\n",
    "                        for Xtrain, Ttrain, Xval, Tval, Xtest, Ttest in mlfuncs.generate_partitions(X, T, n_folds, validation=True,shuffle=True, classification=True):\n",
    "#                             print(f'Doing {struct};{method};{epoch};{learning_rate};{batch_size}')\n",
    "                            Restult = train_this_partition(Xtrain, Ttrain, Xval, Tval, Xtest, Ttest, struct, epoch, method, learning_rate, batch_size)\n",
    "                            resultData.append(Restult)\n",
    "\n",
    "    table = pd.DataFrame(resultData, columns=classes)\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T23:41:37.163016Z",
     "start_time": "2021-10-15T23:41:36.195032Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(((2, 5, 1),), (5,)), 'adam', 10, 0.01, 10, 60.25, 62.0, 58.5]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct = [ [[2, 5, 1]], [5] ]\n",
    "n_epochs = 10\n",
    "method= 'adam'\n",
    "learning_rate = 0.01\n",
    "batch_size = 10\n",
    "\n",
    "n_samples = X.shape[0]\n",
    "rows = np.arange(n_samples)\n",
    "np.random.shuffle(rows)\n",
    "ntrain = int(n_samples * 0.8)\n",
    "nval = int(n_samples * 0.1)\n",
    "Xtrain = X[rows[:ntrain], ...]\n",
    "Ttrain = T[rows[:ntrain], ...]\n",
    "Xval = X[rows[ntrain:ntrain+nval], ...]\n",
    "Tval = T[rows[ntrain:ntrain+nval], ...]\n",
    "Xtest = X[rows[ntrain+nval:], ...]\n",
    "Ttest = T[rows[ntrain+nval:], ...]\n",
    "           \n",
    "result = train_this_partition(Xtrain, Ttrain, Xval, Tval, Xtest, Ttest,\n",
    "                              struct, n_epochs, method, learning_rate, batch_size)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T23:44:04.708062Z",
     "start_time": "2021-10-15T23:42:36.475008Z"
    }
   },
   "outputs": [],
   "source": [
    "# df = run_these_parameters(X, T, n_folds=4,\n",
    "#                          structs=[\n",
    "#                              [ [], [] ],\n",
    "#                              [ [], [10] ],\n",
    "#                              [[[5, 3, 1]], []],\n",
    "#                              [[[20, 3, 2], [5, 3, 1]], [20]],\n",
    "#                             ],\n",
    "#                           methods=['adam'], # , 'sgd'],\n",
    "#                           epochs=[10],\n",
    "#                           learning_rates=[0.01], #, 0.1],\n",
    "#                           batch_sizes=[3])\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments\n",
    "\n",
    "When you have `train_this_partition` and `run_these_parameters`, use them to explore the parameter values, trying to find combinations of parameter values that result in high validation accuracies.  \n",
    "\n",
    "Start with one value for each of the five parameters, but remember to specifiy them as a list of one element, like `learning_rates=[0.01]`.  Then run again with 3 or 4 values for one parameter.  Note the best value.  Use that value for that parameter, then add more values for a different parameter.  \n",
    "\n",
    "Proceed this way for each of the parameter values.  Discuss what you observe after each call to `run_these_parameters` with at least two sentences for each run.  Do the parameter values you find that work best surprise you?  Also discuss how well the validation and test accuracies equal each other.\n",
    "\n",
    "For each method, try various hidden layer structures, learning rates, and numbers of epochs.  Use the validation percent accuracy to pick the best hidden layers, learning rates and numbers of epochs for each method.  Report training, validation and test accuracy for your best validation results for each of the three methods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>struct</th>\n",
       "      <th>method</th>\n",
       "      <th>n_epochs</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>train %</th>\n",
       "      <th>val %</th>\n",
       "      <th>test %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>((), ())</td>\n",
       "      <td>adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>88.5</td>\n",
       "      <td>76.2</td>\n",
       "      <td>71.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>((), ())</td>\n",
       "      <td>adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>90.2</td>\n",
       "      <td>70.4</td>\n",
       "      <td>68.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>((), ())</td>\n",
       "      <td>adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>83.8</td>\n",
       "      <td>72.4</td>\n",
       "      <td>72.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>((), ())</td>\n",
       "      <td>adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>88.5</td>\n",
       "      <td>74.6</td>\n",
       "      <td>76.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>((), ())</td>\n",
       "      <td>adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>82.8</td>\n",
       "      <td>68.2</td>\n",
       "      <td>66.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>((), ())</td>\n",
       "      <td>adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>89.5</td>\n",
       "      <td>73.8</td>\n",
       "      <td>75.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>((), ())</td>\n",
       "      <td>adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>88.3</td>\n",
       "      <td>71.6</td>\n",
       "      <td>72.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>((), ())</td>\n",
       "      <td>adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>88.9</td>\n",
       "      <td>72.2</td>\n",
       "      <td>76.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>((), ())</td>\n",
       "      <td>adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>85.3</td>\n",
       "      <td>68.2</td>\n",
       "      <td>72.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>((), ())</td>\n",
       "      <td>adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>88.5</td>\n",
       "      <td>74.4</td>\n",
       "      <td>76.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>((), ())</td>\n",
       "      <td>adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>87.9</td>\n",
       "      <td>72.8</td>\n",
       "      <td>70.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>((), ())</td>\n",
       "      <td>adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>86.9</td>\n",
       "      <td>72.0</td>\n",
       "      <td>70.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>((), (10,))</td>\n",
       "      <td>adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>86.8</td>\n",
       "      <td>76.6</td>\n",
       "      <td>72.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>((), (10,))</td>\n",
       "      <td>adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>90.5</td>\n",
       "      <td>76.8</td>\n",
       "      <td>74.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>((), (10,))</td>\n",
       "      <td>adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>89.6</td>\n",
       "      <td>78.4</td>\n",
       "      <td>73.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>((), (10,))</td>\n",
       "      <td>adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>89.3</td>\n",
       "      <td>77.2</td>\n",
       "      <td>76.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>((), (10,))</td>\n",
       "      <td>adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>85.8</td>\n",
       "      <td>76.8</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>((), (10,))</td>\n",
       "      <td>adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>85.7</td>\n",
       "      <td>74.4</td>\n",
       "      <td>75.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>((), (10,))</td>\n",
       "      <td>adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>89.2</td>\n",
       "      <td>74.8</td>\n",
       "      <td>73.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>((), (10,))</td>\n",
       "      <td>adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>86.4</td>\n",
       "      <td>78.2</td>\n",
       "      <td>74.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>((), (10,))</td>\n",
       "      <td>adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>84.8</td>\n",
       "      <td>74.8</td>\n",
       "      <td>71.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>((), (10,))</td>\n",
       "      <td>adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>90.8</td>\n",
       "      <td>78.6</td>\n",
       "      <td>78.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>((), (10,))</td>\n",
       "      <td>adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>88.2</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>((), (10,))</td>\n",
       "      <td>adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>83.3</td>\n",
       "      <td>74.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>71.6</td>\n",
       "      <td>58.8</td>\n",
       "      <td>60.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>77.8</td>\n",
       "      <td>69.8</td>\n",
       "      <td>66.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>76.1</td>\n",
       "      <td>65.6</td>\n",
       "      <td>68.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>81.0</td>\n",
       "      <td>70.2</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>64.0</td>\n",
       "      <td>50.6</td>\n",
       "      <td>55.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>84.5</td>\n",
       "      <td>68.4</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>76.3</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>80.4</td>\n",
       "      <td>68.6</td>\n",
       "      <td>71.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>71.8</td>\n",
       "      <td>66.6</td>\n",
       "      <td>65.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>80.6</td>\n",
       "      <td>71.0</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>47.6</td>\n",
       "      <td>45.6</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>79.9</td>\n",
       "      <td>68.4</td>\n",
       "      <td>66.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>(((20, 3, 2), (5, 3, 1)), (20,))</td>\n",
       "      <td>adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>60.8</td>\n",
       "      <td>59.4</td>\n",
       "      <td>62.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>(((20, 3, 2), (5, 3, 1)), (20,))</td>\n",
       "      <td>adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>73.4</td>\n",
       "      <td>72.6</td>\n",
       "      <td>74.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>(((20, 3, 2), (5, 3, 1)), (20,))</td>\n",
       "      <td>adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>77.2</td>\n",
       "      <td>72.8</td>\n",
       "      <td>73.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>(((20, 3, 2), (5, 3, 1)), (20,))</td>\n",
       "      <td>adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>75.7</td>\n",
       "      <td>74.8</td>\n",
       "      <td>74.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>(((20, 3, 2), (5, 3, 1)), (20,))</td>\n",
       "      <td>adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>79.5</td>\n",
       "      <td>78.0</td>\n",
       "      <td>77.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>(((20, 3, 2), (5, 3, 1)), (20,))</td>\n",
       "      <td>adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>78.3</td>\n",
       "      <td>76.2</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>(((20, 3, 2), (5, 3, 1)), (20,))</td>\n",
       "      <td>adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>67.9</td>\n",
       "      <td>69.2</td>\n",
       "      <td>65.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>(((20, 3, 2), (5, 3, 1)), (20,))</td>\n",
       "      <td>adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>77.6</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>(((20, 3, 2), (5, 3, 1)), (20,))</td>\n",
       "      <td>adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>73.8</td>\n",
       "      <td>71.6</td>\n",
       "      <td>72.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>(((20, 3, 2), (5, 3, 1)), (20,))</td>\n",
       "      <td>adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>71.4</td>\n",
       "      <td>68.6</td>\n",
       "      <td>64.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>(((20, 3, 2), (5, 3, 1)), (20,))</td>\n",
       "      <td>adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>72.5</td>\n",
       "      <td>70.6</td>\n",
       "      <td>72.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>(((20, 3, 2), (5, 3, 1)), (20,))</td>\n",
       "      <td>adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>71.8</td>\n",
       "      <td>67.2</td>\n",
       "      <td>64.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              struct method  n_epochs  learning_rate  \\\n",
       "0                           ((), ())   adam        10           0.01   \n",
       "1                           ((), ())   adam        10           0.01   \n",
       "2                           ((), ())   adam        10           0.01   \n",
       "3                           ((), ())   adam        10           0.01   \n",
       "4                           ((), ())   adam        10           0.01   \n",
       "5                           ((), ())   adam        10           0.01   \n",
       "6                           ((), ())   adam        10           0.01   \n",
       "7                           ((), ())   adam        10           0.01   \n",
       "8                           ((), ())   adam        10           0.01   \n",
       "9                           ((), ())   adam        10           0.01   \n",
       "10                          ((), ())   adam        10           0.01   \n",
       "11                          ((), ())   adam        10           0.01   \n",
       "12                       ((), (10,))   adam        10           0.01   \n",
       "13                       ((), (10,))   adam        10           0.01   \n",
       "14                       ((), (10,))   adam        10           0.01   \n",
       "15                       ((), (10,))   adam        10           0.01   \n",
       "16                       ((), (10,))   adam        10           0.01   \n",
       "17                       ((), (10,))   adam        10           0.01   \n",
       "18                       ((), (10,))   adam        10           0.01   \n",
       "19                       ((), (10,))   adam        10           0.01   \n",
       "20                       ((), (10,))   adam        10           0.01   \n",
       "21                       ((), (10,))   adam        10           0.01   \n",
       "22                       ((), (10,))   adam        10           0.01   \n",
       "23                       ((), (10,))   adam        10           0.01   \n",
       "24                (((5, 3, 1),), ())   adam        10           0.01   \n",
       "25                (((5, 3, 1),), ())   adam        10           0.01   \n",
       "26                (((5, 3, 1),), ())   adam        10           0.01   \n",
       "27                (((5, 3, 1),), ())   adam        10           0.01   \n",
       "28                (((5, 3, 1),), ())   adam        10           0.01   \n",
       "29                (((5, 3, 1),), ())   adam        10           0.01   \n",
       "30                (((5, 3, 1),), ())   adam        10           0.01   \n",
       "31                (((5, 3, 1),), ())   adam        10           0.01   \n",
       "32                (((5, 3, 1),), ())   adam        10           0.01   \n",
       "33                (((5, 3, 1),), ())   adam        10           0.01   \n",
       "34                (((5, 3, 1),), ())   adam        10           0.01   \n",
       "35                (((5, 3, 1),), ())   adam        10           0.01   \n",
       "36  (((20, 3, 2), (5, 3, 1)), (20,))   adam        10           0.01   \n",
       "37  (((20, 3, 2), (5, 3, 1)), (20,))   adam        10           0.01   \n",
       "38  (((20, 3, 2), (5, 3, 1)), (20,))   adam        10           0.01   \n",
       "39  (((20, 3, 2), (5, 3, 1)), (20,))   adam        10           0.01   \n",
       "40  (((20, 3, 2), (5, 3, 1)), (20,))   adam        10           0.01   \n",
       "41  (((20, 3, 2), (5, 3, 1)), (20,))   adam        10           0.01   \n",
       "42  (((20, 3, 2), (5, 3, 1)), (20,))   adam        10           0.01   \n",
       "43  (((20, 3, 2), (5, 3, 1)), (20,))   adam        10           0.01   \n",
       "44  (((20, 3, 2), (5, 3, 1)), (20,))   adam        10           0.01   \n",
       "45  (((20, 3, 2), (5, 3, 1)), (20,))   adam        10           0.01   \n",
       "46  (((20, 3, 2), (5, 3, 1)), (20,))   adam        10           0.01   \n",
       "47  (((20, 3, 2), (5, 3, 1)), (20,))   adam        10           0.01   \n",
       "\n",
       "    batch_size  train %  val %  test %  \n",
       "0            3     88.5   76.2    71.4  \n",
       "1            3     90.2   70.4    68.8  \n",
       "2            3     83.8   72.4    72.4  \n",
       "3            3     88.5   74.6    76.6  \n",
       "4            3     82.8   68.2    66.4  \n",
       "5            3     89.5   73.8    75.2  \n",
       "6            3     88.3   71.6    72.4  \n",
       "7            3     88.9   72.2    76.4  \n",
       "8            3     85.3   68.2    72.2  \n",
       "9            3     88.5   74.4    76.4  \n",
       "10           3     87.9   72.8    70.8  \n",
       "11           3     86.9   72.0    70.8  \n",
       "12           3     86.8   76.6    72.2  \n",
       "13           3     90.5   76.8    74.8  \n",
       "14           3     89.6   78.4    73.8  \n",
       "15           3     89.3   77.2    76.4  \n",
       "16           3     85.8   76.8    78.0  \n",
       "17           3     85.7   74.4    75.2  \n",
       "18           3     89.2   74.8    73.2  \n",
       "19           3     86.4   78.2    74.6  \n",
       "20           3     84.8   74.8    71.6  \n",
       "21           3     90.8   78.6    78.4  \n",
       "22           3     88.2   77.0    77.8  \n",
       "23           3     83.3   74.0    75.0  \n",
       "24           3     71.6   58.8    60.8  \n",
       "25           3     77.8   69.8    66.6  \n",
       "26           3     76.1   65.6    68.4  \n",
       "27           3     81.0   70.2    69.0  \n",
       "28           3     64.0   50.6    55.8  \n",
       "29           3     84.5   68.4    70.0  \n",
       "30           3     76.3   70.0    71.0  \n",
       "31           3     80.4   68.6    71.8  \n",
       "32           3     71.8   66.6    65.2  \n",
       "33           3     80.6   71.0    69.0  \n",
       "34           3     47.6   45.6    42.0  \n",
       "35           3     79.9   68.4    66.4  \n",
       "36           3     60.8   59.4    62.2  \n",
       "37           3     73.4   72.6    74.6  \n",
       "38           3     77.2   72.8    73.6  \n",
       "39           3     75.7   74.8    74.2  \n",
       "40           3     79.5   78.0    77.4  \n",
       "41           3     78.3   76.2    75.0  \n",
       "42           3     67.9   69.2    65.2  \n",
       "43           3     77.6   75.0    75.0  \n",
       "44           3     73.8   71.6    72.6  \n",
       "45           3     71.4   68.6    64.6  \n",
       "46           3     72.5   70.6    72.8  \n",
       "47           3     71.8   67.2    64.2  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = run_these_parameters(X, T, n_folds=4,\n",
    "                         structs=[\n",
    "                             [ [], [] ],\n",
    "                             [ [], [10] ],\n",
    "                             [[[5, 3, 1]], []],\n",
    "                             [[[20, 3, 2], [5, 3, 1]], [20]],\n",
    "                            ],\n",
    "                          methods=['adam'], # , 'sgd'],\n",
    "                          epochs=[10],\n",
    "                          learning_rates=[0.01], #, 0.1],\n",
    "                          batch_sizes=[3])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(((5, 3, 1),), ())\tis the best  for structs.\n",
    "The most complex structures does not produces the best results.\n",
    "In most case, result with train set is bette than test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/Desktop/project/CS545/HW/A4grader.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m df = run_these_parameters(X, T, n_folds=4,\n\u001b[0m\u001b[1;32m      2\u001b[0m                          structs=[\n\u001b[1;32m      3\u001b[0m                              \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                             ],\n\u001b[1;32m      5\u001b[0m                           \u001b[0mmethods\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'adam'\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m'sgd'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/project/CS545/HW/A4grader.py\u001b[0m in \u001b[0;36mrun_these_parameters\u001b[0;34m(X, T, n_folds, structs, methods, epochs, learning_rates, batch_sizes)\u001b[0m\n\u001b[1;32m     49\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmlfuncs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_partitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_folds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassification\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m#                             print(f'Doing {struct};{method};{epoch};{learning_rate};{batch_size}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                             \u001b[0mRestult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_this_partition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m                             \u001b[0mresultData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRestult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/project/CS545/HW/A4grader.py\u001b[0m in \u001b[0;36mtrain_this_partition\u001b[0;34m(Xtrain, Ttrain, Xval, Tval, Xtest, Ttest, struct, n_epochs, method, learning_rate, batch_size)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmlfuncs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mnnet_cnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNeuralNetworkClassifier_CNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mnnet_cnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mYval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnnet_cnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/project/CS545/HW/neuralnetworks_A4.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, T, n_epochs, method, learning_rate, momentum, batch_size, verbose)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0;31m# print(f'Training {epoch=} {batchi=}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m                 error = optimizer.step(self._error_f, self._gradient_f, fargs=[Xbatch, Tbatch],\n\u001b[0m\u001b[1;32m    160\u001b[0m                                        learning_rate=learning_rate, momentum=momentum)\n\u001b[1;32m    161\u001b[0m                 \u001b[0mn_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/project/CS545/HW/optimizers.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, error_f, gradient_f, fargs, learning_rate, verbose, error_convert_f, momentum, nesterov)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m                 \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m                 \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/project/CS545/HW/neuralnetworks_A4.py\u001b[0m in \u001b[0;36m_gradient_f\u001b[0;34m(self, X, T)\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;31m# D is delta matrix to be back propagated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backpropagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/project/CS545/HW/neuralnetworks_A4.py\u001b[0m in \u001b[0;36m_backpropagate\u001b[0;34m(self, Delta)\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'G'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m                 \u001b[0mDelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDelta\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m                 \u001b[0mDelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDelta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mYs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayeri\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df = run_these_parameters(X, T, n_folds=4,\n",
    "                         structs=[\n",
    "                             [[[5, 3, 1]], []],           \n",
    "                            ],\n",
    "                          methods=['adam' , 'sgd'],\n",
    "                          epochs=[10],\n",
    "                          learning_rates=[0.01], #, 0.1],\n",
    "                          batch_sizes=[3])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results usign sgd and adam are compareable and all of them are acceptable.\n",
    "Sgd performs slightly better than adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>struct</th>\n",
       "      <th>method</th>\n",
       "      <th>n_epochs</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>train %</th>\n",
       "      <th>val %</th>\n",
       "      <th>test %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>97.50</td>\n",
       "      <td>67.5</td>\n",
       "      <td>77.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>98.75</td>\n",
       "      <td>72.5</td>\n",
       "      <td>87.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>97.50</td>\n",
       "      <td>92.5</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>98.75</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>98.75</td>\n",
       "      <td>70.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>97.50</td>\n",
       "      <td>92.5</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>98.75</td>\n",
       "      <td>82.5</td>\n",
       "      <td>67.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>97.50</td>\n",
       "      <td>70.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>98.75</td>\n",
       "      <td>80.0</td>\n",
       "      <td>67.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>98.75</td>\n",
       "      <td>82.5</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>96.25</td>\n",
       "      <td>72.5</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>98.75</td>\n",
       "      <td>70.0</td>\n",
       "      <td>82.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>98.75</td>\n",
       "      <td>82.5</td>\n",
       "      <td>87.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>98.75</td>\n",
       "      <td>75.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>85.0</td>\n",
       "      <td>82.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>90.0</td>\n",
       "      <td>87.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>98.75</td>\n",
       "      <td>82.5</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>80.0</td>\n",
       "      <td>82.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>82.5</td>\n",
       "      <td>77.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>82.5</td>\n",
       "      <td>77.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>82.5</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>80.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>85.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>72.5</td>\n",
       "      <td>82.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>30</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>72.5</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>30</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>30</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>82.5</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>30</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>98.75</td>\n",
       "      <td>87.5</td>\n",
       "      <td>77.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>30</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>72.5</td>\n",
       "      <td>72.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>30</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>82.5</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>30</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>75.0</td>\n",
       "      <td>72.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>30</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>30</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>90.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>30</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>97.50</td>\n",
       "      <td>77.5</td>\n",
       "      <td>82.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>30</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>67.5</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>30</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>75.0</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                struct method  n_epochs  learning_rate  batch_size  train %  \\\n",
       "0   (((5, 3, 1),), ())    sgd        10           0.01           3    97.50   \n",
       "1   (((5, 3, 1),), ())    sgd        10           0.01           3    98.75   \n",
       "2   (((5, 3, 1),), ())    sgd        10           0.01           3    97.50   \n",
       "3   (((5, 3, 1),), ())    sgd        10           0.01           3    98.75   \n",
       "4   (((5, 3, 1),), ())    sgd        10           0.01           3    98.75   \n",
       "5   (((5, 3, 1),), ())    sgd        10           0.01           3    97.50   \n",
       "6   (((5, 3, 1),), ())    sgd        10           0.01           3    98.75   \n",
       "7   (((5, 3, 1),), ())    sgd        10           0.01           3    97.50   \n",
       "8   (((5, 3, 1),), ())    sgd        10           0.01           3    98.75   \n",
       "9   (((5, 3, 1),), ())    sgd        10           0.01           3    98.75   \n",
       "10  (((5, 3, 1),), ())    sgd        10           0.01           3    96.25   \n",
       "11  (((5, 3, 1),), ())    sgd        10           0.01           3    98.75   \n",
       "12  (((5, 3, 1),), ())    sgd        20           0.01           3    98.75   \n",
       "13  (((5, 3, 1),), ())    sgd        20           0.01           3    98.75   \n",
       "14  (((5, 3, 1),), ())    sgd        20           0.01           3   100.00   \n",
       "15  (((5, 3, 1),), ())    sgd        20           0.01           3   100.00   \n",
       "16  (((5, 3, 1),), ())    sgd        20           0.01           3    98.75   \n",
       "17  (((5, 3, 1),), ())    sgd        20           0.01           3   100.00   \n",
       "18  (((5, 3, 1),), ())    sgd        20           0.01           3   100.00   \n",
       "19  (((5, 3, 1),), ())    sgd        20           0.01           3   100.00   \n",
       "20  (((5, 3, 1),), ())    sgd        20           0.01           3   100.00   \n",
       "21  (((5, 3, 1),), ())    sgd        20           0.01           3   100.00   \n",
       "22  (((5, 3, 1),), ())    sgd        20           0.01           3   100.00   \n",
       "23  (((5, 3, 1),), ())    sgd        20           0.01           3   100.00   \n",
       "24  (((5, 3, 1),), ())    sgd        30           0.01           3   100.00   \n",
       "25  (((5, 3, 1),), ())    sgd        30           0.01           3   100.00   \n",
       "26  (((5, 3, 1),), ())    sgd        30           0.01           3   100.00   \n",
       "27  (((5, 3, 1),), ())    sgd        30           0.01           3    98.75   \n",
       "28  (((5, 3, 1),), ())    sgd        30           0.01           3   100.00   \n",
       "29  (((5, 3, 1),), ())    sgd        30           0.01           3   100.00   \n",
       "30  (((5, 3, 1),), ())    sgd        30           0.01           3   100.00   \n",
       "31  (((5, 3, 1),), ())    sgd        30           0.01           3   100.00   \n",
       "32  (((5, 3, 1),), ())    sgd        30           0.01           3   100.00   \n",
       "33  (((5, 3, 1),), ())    sgd        30           0.01           3    97.50   \n",
       "34  (((5, 3, 1),), ())    sgd        30           0.01           3   100.00   \n",
       "35  (((5, 3, 1),), ())    sgd        30           0.01           3   100.00   \n",
       "\n",
       "    val %  test %  \n",
       "0    67.5    77.5  \n",
       "1    72.5    87.5  \n",
       "2    92.5    90.0  \n",
       "3    75.0    70.0  \n",
       "4    70.0    80.0  \n",
       "5    92.5    75.0  \n",
       "6    82.5    67.5  \n",
       "7    70.0    75.0  \n",
       "8    80.0    67.5  \n",
       "9    82.5    95.0  \n",
       "10   72.5    90.0  \n",
       "11   70.0    82.5  \n",
       "12   82.5    87.5  \n",
       "13   75.0    80.0  \n",
       "14   85.0    82.5  \n",
       "15   90.0    87.5  \n",
       "16   82.5    85.0  \n",
       "17   80.0    82.5  \n",
       "18   82.5    77.5  \n",
       "19   82.5    77.5  \n",
       "20   82.5    70.0  \n",
       "21   80.0    75.0  \n",
       "22   85.0    80.0  \n",
       "23   72.5    82.5  \n",
       "24   72.5    85.0  \n",
       "25   80.0    77.5  \n",
       "26   82.5    75.0  \n",
       "27   87.5    77.5  \n",
       "28   72.5    72.5  \n",
       "29   82.5    75.0  \n",
       "30   75.0    72.5  \n",
       "31   75.0    75.0  \n",
       "32   90.0    75.0  \n",
       "33   77.5    82.5  \n",
       "34   67.5    75.0  \n",
       "35   75.0    85.0  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = run_these_parameters(X, T, n_folds=4,\n",
    "                         structs=[\n",
    "                             [[[5, 3, 1]], []],           \n",
    "                            ],\n",
    "                          methods=['sgd'],\n",
    "                          epochs=[10,20,30],\n",
    "                          learning_rates=[0.01], #, 0.1],\n",
    "                          batch_sizes=[3])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results using 10,20,30 are comparable with 20 better than others.\n",
    "Probably because the batch size was set too small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>struct</th>\n",
       "      <th>method</th>\n",
       "      <th>n_epochs</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>train %</th>\n",
       "      <th>val %</th>\n",
       "      <th>test %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>67.5</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>72.5</td>\n",
       "      <td>87.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>67.5</td>\n",
       "      <td>82.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>85.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>97.50</td>\n",
       "      <td>90.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>98.75</td>\n",
       "      <td>90.0</td>\n",
       "      <td>87.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>75.0</td>\n",
       "      <td>92.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>65.0</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>82.5</td>\n",
       "      <td>67.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>72.5</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>82.5</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>67.5</td>\n",
       "      <td>62.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>80.0</td>\n",
       "      <td>82.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>75.0</td>\n",
       "      <td>57.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>62.5</td>\n",
       "      <td>72.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>67.5</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>80.0</td>\n",
       "      <td>82.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>85.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>80.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>55.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>77.5</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>75.0</td>\n",
       "      <td>77.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "      <td>97.50</td>\n",
       "      <td>67.5</td>\n",
       "      <td>77.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>72.5</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "      <td>98.75</td>\n",
       "      <td>62.5</td>\n",
       "      <td>77.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "      <td>97.50</td>\n",
       "      <td>75.0</td>\n",
       "      <td>67.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "      <td>97.50</td>\n",
       "      <td>62.5</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "      <td>98.75</td>\n",
       "      <td>65.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "      <td>97.50</td>\n",
       "      <td>77.5</td>\n",
       "      <td>77.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "      <td>98.75</td>\n",
       "      <td>82.5</td>\n",
       "      <td>82.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>70.0</td>\n",
       "      <td>72.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "      <td>98.75</td>\n",
       "      <td>72.5</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>75.0</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "      <td>98.75</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                struct method  n_epochs  learning_rate  batch_size  train %  \\\n",
       "0   (((5, 3, 1),), ())    sgd        20           0.01           3   100.00   \n",
       "1   (((5, 3, 1),), ())    sgd        20           0.01           3   100.00   \n",
       "2   (((5, 3, 1),), ())    sgd        20           0.01           3   100.00   \n",
       "3   (((5, 3, 1),), ())    sgd        20           0.01           3   100.00   \n",
       "4   (((5, 3, 1),), ())    sgd        20           0.01           3    97.50   \n",
       "5   (((5, 3, 1),), ())    sgd        20           0.01           3   100.00   \n",
       "6   (((5, 3, 1),), ())    sgd        20           0.01           3    98.75   \n",
       "7   (((5, 3, 1),), ())    sgd        20           0.01           3   100.00   \n",
       "8   (((5, 3, 1),), ())    sgd        20           0.01           3   100.00   \n",
       "9   (((5, 3, 1),), ())    sgd        20           0.01           3   100.00   \n",
       "10  (((5, 3, 1),), ())    sgd        20           0.01           3   100.00   \n",
       "11  (((5, 3, 1),), ())    sgd        20           0.01           3   100.00   \n",
       "12  (((5, 3, 1),), ())    sgd        20           0.05           3   100.00   \n",
       "13  (((5, 3, 1),), ())    sgd        20           0.05           3   100.00   \n",
       "14  (((5, 3, 1),), ())    sgd        20           0.05           3   100.00   \n",
       "15  (((5, 3, 1),), ())    sgd        20           0.05           3   100.00   \n",
       "16  (((5, 3, 1),), ())    sgd        20           0.05           3   100.00   \n",
       "17  (((5, 3, 1),), ())    sgd        20           0.05           3   100.00   \n",
       "18  (((5, 3, 1),), ())    sgd        20           0.05           3   100.00   \n",
       "19  (((5, 3, 1),), ())    sgd        20           0.05           3   100.00   \n",
       "20  (((5, 3, 1),), ())    sgd        20           0.05           3   100.00   \n",
       "21  (((5, 3, 1),), ())    sgd        20           0.05           3   100.00   \n",
       "22  (((5, 3, 1),), ())    sgd        20           0.05           3   100.00   \n",
       "23  (((5, 3, 1),), ())    sgd        20           0.05           3   100.00   \n",
       "24  (((5, 3, 1),), ())    sgd        20           0.10           3    97.50   \n",
       "25  (((5, 3, 1),), ())    sgd        20           0.10           3   100.00   \n",
       "26  (((5, 3, 1),), ())    sgd        20           0.10           3    98.75   \n",
       "27  (((5, 3, 1),), ())    sgd        20           0.10           3    97.50   \n",
       "28  (((5, 3, 1),), ())    sgd        20           0.10           3    97.50   \n",
       "29  (((5, 3, 1),), ())    sgd        20           0.10           3    98.75   \n",
       "30  (((5, 3, 1),), ())    sgd        20           0.10           3    97.50   \n",
       "31  (((5, 3, 1),), ())    sgd        20           0.10           3    98.75   \n",
       "32  (((5, 3, 1),), ())    sgd        20           0.10           3   100.00   \n",
       "33  (((5, 3, 1),), ())    sgd        20           0.10           3    98.75   \n",
       "34  (((5, 3, 1),), ())    sgd        20           0.10           3   100.00   \n",
       "35  (((5, 3, 1),), ())    sgd        20           0.10           3    98.75   \n",
       "\n",
       "    val %  test %  \n",
       "0    67.5    80.0  \n",
       "1    72.5    87.5  \n",
       "2    67.5    82.5  \n",
       "3    85.0    70.0  \n",
       "4    90.0    80.0  \n",
       "5    80.0    80.0  \n",
       "6    90.0    87.5  \n",
       "7    75.0    92.5  \n",
       "8    65.0    85.0  \n",
       "9    82.5    67.5  \n",
       "10   72.5    75.0  \n",
       "11   82.5    70.0  \n",
       "12   67.5    62.5  \n",
       "13   80.0    82.5  \n",
       "14   75.0    57.5  \n",
       "15   62.5    72.5  \n",
       "16   67.5    75.0  \n",
       "17   80.0    82.5  \n",
       "18   85.0    75.0  \n",
       "19   80.0    75.0  \n",
       "20   80.0    77.5  \n",
       "21   55.0    70.0  \n",
       "22   77.5    75.0  \n",
       "23   75.0    77.5  \n",
       "24   67.5    77.5  \n",
       "25   72.5    75.0  \n",
       "26   62.5    77.5  \n",
       "27   75.0    67.5  \n",
       "28   62.5    75.0  \n",
       "29   65.0    75.0  \n",
       "30   77.5    77.5  \n",
       "31   82.5    82.5  \n",
       "32   70.0    72.5  \n",
       "33   72.5    60.0  \n",
       "34   75.0    65.0  \n",
       "35   70.0    70.0  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = run_these_parameters(X, T, n_folds=4,\n",
    "                         structs=[\n",
    "                             [[[5, 3, 1]], []],           \n",
    "                            ],\n",
    "                          methods=['sgd'],\n",
    "                          epochs=[20],\n",
    "                          learning_rates=[0.01,0.05,0.1], #, 0.1],\n",
    "                          batch_sizes=[3])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/Desktop/project/CS545/HW/A4grader.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m df = run_these_parameters(X, T, n_folds=4,\n\u001b[0m\u001b[1;32m      2\u001b[0m                          structs=[\n\u001b[1;32m      3\u001b[0m                              \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                             ],\n\u001b[1;32m      5\u001b[0m                           \u001b[0mmethods\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sgd'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/project/CS545/HW/A4grader.py\u001b[0m in \u001b[0;36mrun_these_parameters\u001b[0;34m(X, T, n_folds, structs, methods, epochs, learning_rates, batch_sizes)\u001b[0m\n\u001b[1;32m     49\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmlfuncs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_partitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_folds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassification\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m#                             print(f'Doing {struct};{method};{epoch};{learning_rate};{batch_size}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                             \u001b[0mRestult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_this_partition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m                             \u001b[0mresultData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRestult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/project/CS545/HW/A4grader.py\u001b[0m in \u001b[0;36mtrain_this_partition\u001b[0;34m(Xtrain, Ttrain, Xval, Tval, Xtest, Ttest, struct, n_epochs, method, learning_rate, batch_size)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmlfuncs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mnnet_cnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNeuralNetworkClassifier_CNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mnnet_cnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mYval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnnet_cnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/project/CS545/HW/neuralnetworks_A4.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, T, n_epochs, method, learning_rate, momentum, batch_size, verbose)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0;31m# print(f'Training {epoch=} {batchi=}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m                 error = optimizer.step(self._error_f, self._gradient_f, fargs=[Xbatch, Tbatch],\n\u001b[0m\u001b[1;32m    160\u001b[0m                                        learning_rate=learning_rate, momentum=momentum)\n\u001b[1;32m    161\u001b[0m                 \u001b[0mn_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/project/CS545/HW/optimizers.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, error_f, gradient_f, fargs, learning_rate, verbose, error_convert_f, momentum, nesterov)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m                 \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m                 \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnesterov\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/project/CS545/HW/neuralnetworks_A4.py\u001b[0m in \u001b[0;36m_gradient_f\u001b[0;34m(self, X, T)\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;31m# D is delta matrix to be back propagated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backpropagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/project/CS545/HW/neuralnetworks_A4.py\u001b[0m in \u001b[0;36m_backpropagate\u001b[0;34m(self, Delta)\u001b[0m\n\u001b[1;32m    426\u001b[0m                 \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUprev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYin_patches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m                 \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mU\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDelta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m                 \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mYin_patches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mD\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mK\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mUprev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mDelta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mD\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m                 \u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'G'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'G'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDelta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df = run_these_parameters(X, T, n_folds=4,\n",
    "                         structs=[\n",
    "                             [[[5, 3, 1]], []],           \n",
    "                            ],\n",
    "                          methods=['sgd'],\n",
    "                          epochs=[20],\n",
    "                          learning_rates=[0.01,0.05,0.1], #, 0.1],\n",
    "                          batch_sizes=[3])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With   learning_rates=[0.01,0.05,0.1], the rate=0.01 performance best.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>struct</th>\n",
       "      <th>method</th>\n",
       "      <th>n_epochs</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>train %</th>\n",
       "      <th>val %</th>\n",
       "      <th>test %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>87.5</td>\n",
       "      <td>82.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>80.0</td>\n",
       "      <td>82.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>70.0</td>\n",
       "      <td>77.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>98.75</td>\n",
       "      <td>80.0</td>\n",
       "      <td>87.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>77.5</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>80.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>98.75</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>82.5</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>85.0</td>\n",
       "      <td>82.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>72.5</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>98.75</td>\n",
       "      <td>87.5</td>\n",
       "      <td>77.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>82.5</td>\n",
       "      <td>87.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>100.00</td>\n",
       "      <td>85.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>100.00</td>\n",
       "      <td>87.5</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>100.00</td>\n",
       "      <td>75.0</td>\n",
       "      <td>67.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>98.75</td>\n",
       "      <td>85.0</td>\n",
       "      <td>87.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>100.00</td>\n",
       "      <td>92.5</td>\n",
       "      <td>87.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>100.00</td>\n",
       "      <td>77.5</td>\n",
       "      <td>87.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>100.00</td>\n",
       "      <td>87.5</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>100.00</td>\n",
       "      <td>87.5</td>\n",
       "      <td>87.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>100.00</td>\n",
       "      <td>77.5</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>100.00</td>\n",
       "      <td>75.0</td>\n",
       "      <td>87.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>98.75</td>\n",
       "      <td>87.5</td>\n",
       "      <td>77.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>100.00</td>\n",
       "      <td>90.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20</td>\n",
       "      <td>95.00</td>\n",
       "      <td>82.5</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20</td>\n",
       "      <td>90.00</td>\n",
       "      <td>70.0</td>\n",
       "      <td>82.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20</td>\n",
       "      <td>96.25</td>\n",
       "      <td>80.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20</td>\n",
       "      <td>93.75</td>\n",
       "      <td>90.0</td>\n",
       "      <td>82.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20</td>\n",
       "      <td>93.75</td>\n",
       "      <td>70.0</td>\n",
       "      <td>77.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20</td>\n",
       "      <td>93.75</td>\n",
       "      <td>75.0</td>\n",
       "      <td>77.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20</td>\n",
       "      <td>93.75</td>\n",
       "      <td>80.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20</td>\n",
       "      <td>96.25</td>\n",
       "      <td>80.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20</td>\n",
       "      <td>92.50</td>\n",
       "      <td>77.5</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20</td>\n",
       "      <td>95.00</td>\n",
       "      <td>87.5</td>\n",
       "      <td>82.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20</td>\n",
       "      <td>95.00</td>\n",
       "      <td>77.5</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20</td>\n",
       "      <td>96.25</td>\n",
       "      <td>87.5</td>\n",
       "      <td>77.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30</td>\n",
       "      <td>91.25</td>\n",
       "      <td>82.5</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30</td>\n",
       "      <td>96.25</td>\n",
       "      <td>80.0</td>\n",
       "      <td>82.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30</td>\n",
       "      <td>95.00</td>\n",
       "      <td>80.0</td>\n",
       "      <td>82.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30</td>\n",
       "      <td>95.00</td>\n",
       "      <td>77.5</td>\n",
       "      <td>82.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30</td>\n",
       "      <td>90.00</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30</td>\n",
       "      <td>97.50</td>\n",
       "      <td>77.5</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30</td>\n",
       "      <td>93.75</td>\n",
       "      <td>77.5</td>\n",
       "      <td>77.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30</td>\n",
       "      <td>95.00</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30</td>\n",
       "      <td>97.50</td>\n",
       "      <td>77.5</td>\n",
       "      <td>77.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30</td>\n",
       "      <td>92.50</td>\n",
       "      <td>82.5</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30</td>\n",
       "      <td>97.50</td>\n",
       "      <td>77.5</td>\n",
       "      <td>72.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>(((5, 3, 1),), ())</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30</td>\n",
       "      <td>92.50</td>\n",
       "      <td>75.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                struct method  n_epochs  learning_rate  batch_size  train %  \\\n",
       "0   (((5, 3, 1),), ())    sgd        20           0.01           3   100.00   \n",
       "1   (((5, 3, 1),), ())    sgd        20           0.01           3   100.00   \n",
       "2   (((5, 3, 1),), ())    sgd        20           0.01           3   100.00   \n",
       "3   (((5, 3, 1),), ())    sgd        20           0.01           3    98.75   \n",
       "4   (((5, 3, 1),), ())    sgd        20           0.01           3   100.00   \n",
       "5   (((5, 3, 1),), ())    sgd        20           0.01           3   100.00   \n",
       "6   (((5, 3, 1),), ())    sgd        20           0.01           3    98.75   \n",
       "7   (((5, 3, 1),), ())    sgd        20           0.01           3   100.00   \n",
       "8   (((5, 3, 1),), ())    sgd        20           0.01           3   100.00   \n",
       "9   (((5, 3, 1),), ())    sgd        20           0.01           3   100.00   \n",
       "10  (((5, 3, 1),), ())    sgd        20           0.01           3    98.75   \n",
       "11  (((5, 3, 1),), ())    sgd        20           0.01           3   100.00   \n",
       "12  (((5, 3, 1),), ())    sgd        20           0.01           5   100.00   \n",
       "13  (((5, 3, 1),), ())    sgd        20           0.01           5   100.00   \n",
       "14  (((5, 3, 1),), ())    sgd        20           0.01           5   100.00   \n",
       "15  (((5, 3, 1),), ())    sgd        20           0.01           5    98.75   \n",
       "16  (((5, 3, 1),), ())    sgd        20           0.01           5   100.00   \n",
       "17  (((5, 3, 1),), ())    sgd        20           0.01           5   100.00   \n",
       "18  (((5, 3, 1),), ())    sgd        20           0.01           5   100.00   \n",
       "19  (((5, 3, 1),), ())    sgd        20           0.01           5   100.00   \n",
       "20  (((5, 3, 1),), ())    sgd        20           0.01           5   100.00   \n",
       "21  (((5, 3, 1),), ())    sgd        20           0.01           5   100.00   \n",
       "22  (((5, 3, 1),), ())    sgd        20           0.01           5    98.75   \n",
       "23  (((5, 3, 1),), ())    sgd        20           0.01           5   100.00   \n",
       "24  (((5, 3, 1),), ())    sgd        20           0.01          20    95.00   \n",
       "25  (((5, 3, 1),), ())    sgd        20           0.01          20    90.00   \n",
       "26  (((5, 3, 1),), ())    sgd        20           0.01          20    96.25   \n",
       "27  (((5, 3, 1),), ())    sgd        20           0.01          20    93.75   \n",
       "28  (((5, 3, 1),), ())    sgd        20           0.01          20    93.75   \n",
       "29  (((5, 3, 1),), ())    sgd        20           0.01          20    93.75   \n",
       "30  (((5, 3, 1),), ())    sgd        20           0.01          20    93.75   \n",
       "31  (((5, 3, 1),), ())    sgd        20           0.01          20    96.25   \n",
       "32  (((5, 3, 1),), ())    sgd        20           0.01          20    92.50   \n",
       "33  (((5, 3, 1),), ())    sgd        20           0.01          20    95.00   \n",
       "34  (((5, 3, 1),), ())    sgd        20           0.01          20    95.00   \n",
       "35  (((5, 3, 1),), ())    sgd        20           0.01          20    96.25   \n",
       "36  (((5, 3, 1),), ())    sgd        20           0.01          30    91.25   \n",
       "37  (((5, 3, 1),), ())    sgd        20           0.01          30    96.25   \n",
       "38  (((5, 3, 1),), ())    sgd        20           0.01          30    95.00   \n",
       "39  (((5, 3, 1),), ())    sgd        20           0.01          30    95.00   \n",
       "40  (((5, 3, 1),), ())    sgd        20           0.01          30    90.00   \n",
       "41  (((5, 3, 1),), ())    sgd        20           0.01          30    97.50   \n",
       "42  (((5, 3, 1),), ())    sgd        20           0.01          30    93.75   \n",
       "43  (((5, 3, 1),), ())    sgd        20           0.01          30    95.00   \n",
       "44  (((5, 3, 1),), ())    sgd        20           0.01          30    97.50   \n",
       "45  (((5, 3, 1),), ())    sgd        20           0.01          30    92.50   \n",
       "46  (((5, 3, 1),), ())    sgd        20           0.01          30    97.50   \n",
       "47  (((5, 3, 1),), ())    sgd        20           0.01          30    92.50   \n",
       "\n",
       "    val %  test %  \n",
       "0    87.5    82.5  \n",
       "1    80.0    82.5  \n",
       "2    70.0    77.5  \n",
       "3    80.0    87.5  \n",
       "4    77.5    80.0  \n",
       "5    80.0    90.0  \n",
       "6    80.0    80.0  \n",
       "7    82.5    80.0  \n",
       "8    85.0    82.5  \n",
       "9    72.5    70.0  \n",
       "10   87.5    77.5  \n",
       "11   82.5    87.5  \n",
       "12   85.0    90.0  \n",
       "13   87.5    85.0  \n",
       "14   75.0    67.5  \n",
       "15   85.0    87.5  \n",
       "16   92.5    87.5  \n",
       "17   77.5    87.5  \n",
       "18   87.5    90.0  \n",
       "19   87.5    87.5  \n",
       "20   77.5    90.0  \n",
       "21   75.0    87.5  \n",
       "22   87.5    77.5  \n",
       "23   90.0    80.0  \n",
       "24   82.5    90.0  \n",
       "25   70.0    82.5  \n",
       "26   80.0    90.0  \n",
       "27   90.0    82.5  \n",
       "28   70.0    77.5  \n",
       "29   75.0    77.5  \n",
       "30   80.0    70.0  \n",
       "31   80.0    75.0  \n",
       "32   77.5    85.0  \n",
       "33   87.5    82.5  \n",
       "34   77.5    75.0  \n",
       "35   87.5    77.5  \n",
       "36   82.5    80.0  \n",
       "37   80.0    82.5  \n",
       "38   80.0    82.5  \n",
       "39   77.5    82.5  \n",
       "40   80.0    77.5  \n",
       "41   77.5    85.0  \n",
       "42   77.5    77.5  \n",
       "43   80.0    80.0  \n",
       "44   77.5    77.5  \n",
       "45   82.5    80.0  \n",
       "46   77.5    72.5  \n",
       "47   75.0    80.0  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = run_these_parameters(X, T, n_folds=4,\n",
    "                         structs=[\n",
    "                             [[[5, 3, 1]], []],           \n",
    "                            ],\n",
    "                          methods=['sgd'],\n",
    "                          epochs=[20],\n",
    "                          learning_rates=[0.01], #, 0.1],\n",
    "                          batch_sizes=[3,5,20,30])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tried batch_sizes=[3,5,20,30]), and looks like batch size=30 performs best.\n",
    "This is due to when batch size is sufficiently large, the pattern difference between the train set and the test set are reduced. \n",
    "\n",
    "\n",
    "Do the parameter values you find that work best surprise you? Also discuss how well the validation and test accuracies equal each other.\n",
    "\n",
    "The best parameter values I found out is  \"\n",
    "                         structs=[\n",
    "                             [[[5, 3, 1]], []],           \n",
    "                            ],\n",
    "                          methods=['sgd'],\n",
    "                          epochs=[20],\n",
    "                          learning_rates=[0.01], #, 0.1],\n",
    "                          batch_sizes=[30])\n",
    "\"\n",
    "It does not surprise me. The validation and test accuracies are acceptablely close to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df = run_these_parameters(X, T, n_folds=5,\n",
    "                         structs=[\n",
    "                             [ [], [] ],\n",
    "                             [ [], [10] ],\n",
    "                             [[[5, 3, 1]], []],\n",
    "                             [[[20, 3, 2], [5, 3, 1]], [20]], \n",
    "                            ],\n",
    "                          methods=['sgd','adam'],\n",
    "                          epochs=[30],\n",
    "                          learning_rates=[0.01,0.05,0.1], #, 0.1],\n",
    "                          batch_sizes=[30])\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each method, try various hidden layer structures, learning rates, and numbers of epochs. Use the validation percent accuracy to pick the best hidden layers, learning rates and numbers of epochs for each method. Report training, validation and test accuracy for your best validation results for each of the three methods.\n",
    "\n",
    "For meshod adam, the best combination happen to be \n",
    "\n",
    "  structs=[\n",
    "                           \n",
    "                             [[[5, 3, 1]], []],\n",
    "                              \n",
    "                            ],\n",
    "                           \n",
    "                          epochs=[20],\n",
    "                          learning_rates=[0.01],\n",
    "                          batch_sizes=[30])\n",
    "\n",
    "The accuracy is training=100.00\tvalidation=90.5\ttest=87.5\n",
    "\n",
    "For method sgd, the best combination happen to be \n",
    "\n",
    "  structs=[ [[[20, 3, 2], [5, 3, 1]], [20]] ],                   \n",
    "                          epochs=[20],\n",
    "                          learning_rates=[0.01],\n",
    "                          batch_sizes=[30])\n",
    "\n",
    "The accuracy is    training100\tvalidation=92.5\ttest=85\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T20:44:33.927450Z",
     "start_time": "2020-10-16T20:44:33.925092Z"
    }
   },
   "source": [
    "# Grading\n",
    "\n",
    "(UPDATED Oct. 21, 9:35am, tolerance on accuracies is now larger) Download [A4grader.tar](https://www.cs.colostate.edu/~anderson/cs545/notebooks/A4grader.tar), extract `A4grader.py` before running the following cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-18T14:52:02.691904Z",
     "start_time": "2021-10-18T14:51:57.734208Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================= Code Execution =======================\n",
      "\n",
      "Extracting python code from notebook named 'Chen-A4.ipynb' and storing in notebookcode.py\n",
      "Removing all statements that are not function or class defs or import statements.\n",
      "\n",
      "===========================================================================================\n",
      "Testing:\n",
      "\n",
      "    def make_images(n_each_class):\n",
      "        images = np.zeros((n_each_class * 2, 20, 20))  # nSamples, rows, columns\n",
      "        radii = 3 + np.random.randint(10 - 5, size=(n_each_class * 2, 1))\n",
      "        centers = np.zeros((n_each_class * 2, 2))\n",
      "        for i in range(n_each_class * 2):\n",
      "            r = radii[i, 0]\n",
      "            centers[i, :] = r + 1 + np.random.randint(18 - 2 * r, size=(1, 2))\n",
      "            x = int(centers[i, 0])\n",
      "            y = int(centers[i, 1])\n",
      "            if i < n_each_class:\n",
      "                # squares\n",
      "                images[i, x - r:x + r, y + r] = 1.0\n",
      "                images[i, x - r:x + r, y - r] = 1.0\n",
      "                images[i, x - r, y - r:y + r] = 1.0\n",
      "                images[i, x + r, y - r:y + r + 1] = 1.0\n",
      "            else:\n",
      "                # diamonds\n",
      "                images[i, range(x - r, x), range(y, y + r)] = 1.0\n",
      "                images[i, range(x - r, x), range(y, y - r, -1)] = 1.0\n",
      "                images[i, range(x, x + r + 1), range(y + r, y - 1, -1)] = 1.0\n",
      "                images[i, range(x, x + r), range(y - r, y)] = 1.0\n",
      "        T = np.array(['square'] * n_each_class + ['diamond'] * n_each_class).reshape(-1, 1)\n",
      "        n, r, c = images.shape\n",
      "        images = images.reshape(n, r, c, 1)  # add channel dimsension\n",
      "        return images, T\n",
      "\n",
      "    np.random.seed(4200)\n",
      "\n",
      "    n_each_class = 10\n",
      "    Xtrain, Ttrain = make_images(n_each_class * 2)\n",
      "    Xval, Tval = make_images(n_each_class)\n",
      "    Xtest, Ttest = make_images(n_each_class)\n",
      "    print(Xtrain.shape, Ttrain.shape, Xval.shape, Tval.shape, Xtest.shape, Ttest.shape)\n",
      "\n",
      "    struct = [ [[2, 5, 1]], [5] ]\n",
      "    n_epochs = 20\n",
      "    method= 'adam'\n",
      "    learning_rate = 0.01\n",
      "    batch_size = 5\n",
      "\n",
      "    result = train_this_partition(Xtrain, Ttrain, Xval, Tval, Xtest, Ttest,\n",
      "                                   struct, n_epochs, method, learning_rate, batch_size)\n",
      "\n",
      "(40, 20, 20, 1) (40, 1) (20, 20, 20, 1) (20, 1) (20, 20, 20, 1) (20, 1)\n",
      "\n",
      "---  20 / 20 points. train_this_partition correctly returns\n",
      " [(((2, 5, 1),), (5,)), 'adam', 20, 0.01, 5, 97.5, 75.0, 70.0]\n",
      "\n",
      "===========================================================================================\n",
      "Testing\n",
      "\n",
      "    np.random.seed(4200)\n",
      "\n",
      "    n_each_class = 10\n",
      "    Xtrain, Ttrain = make_images(n_each_class * 2)\n",
      "    Xval, Tval = make_images(n_each_class)\n",
      "    Xtest, Ttest = make_images(n_each_class)\n",
      "    print(Xtrain.shape, Ttrain.shape, Xval.shape, Tval.shape, Xtest.shape, Ttest.shape)\n",
      "\n",
      "    structs = [ [[], []],\n",
      "                [[], [10]],\n",
      "                [[[4, 5, 1], [5, 3, 1]], [5]]\n",
      "               ]\n",
      "    n_epochs = [10, 20]\n",
      "    methods= ['adam']\n",
      "    learning_rates = [0.01, 0.1]\n",
      "    batch_sizes = [5]\n",
      "\n",
      "    results = []\n",
      "    for struct in structs:\n",
      "        for epochs in n_epochs:\n",
      "            for method in methods:\n",
      "                for learning_rate in learning_rates:\n",
      "                    for batch_size in batch_sizes:\n",
      "                    \n",
      "                        # This next for loop simulates how you will use generate_partitions\n",
      "                        # in run_these_parameters\n",
      "                        for Xtrain, Ttrain, Xval, Tval, Xtest, Ttest in [[Xtrain, Ttrain, Xval, Tval, Xtest, Ttest]]:\n",
      "                            result = train_this_partition(Xtrain, Ttrain, Xval, Tval, Xtest, Ttest,\n",
      "                                                          struct, epochs, method, learning_rate, batch_size)\n",
      "                            results.append(result)\n",
      "\n",
      "(40, 20, 20, 1) (40, 1) (20, 20, 20, 1) (20, 1) (20, 20, 20, 1) (20, 1)\n",
      "\n",
      "--- 20 / 20 points. train_this_partition correctly returns\n",
      "[((), ()), 'adam', 10, 0.01, 5, 100.0, 65.0, 65.0]\n",
      "[((), ()), 'adam', 10, 0.1, 5, 100.0, 70.0, 65.0]\n",
      "[((), ()), 'adam', 20, 0.01, 5, 100.0, 70.0, 65.0]\n",
      "[((), ()), 'adam', 20, 0.1, 5, 100.0, 60.0, 75.0]\n",
      "[((), (10,)), 'adam', 10, 0.01, 5, 100.0, 70.0, 80.0]\n",
      "[((), (10,)), 'adam', 10, 0.1, 5, 100.0, 70.0, 70.0]\n",
      "[((), (10,)), 'adam', 20, 0.01, 5, 100.0, 70.0, 75.0]\n",
      "[((), (10,)), 'adam', 20, 0.1, 5, 100.0, 75.0, 80.0]\n",
      "[(((4, 5, 1), (5, 3, 1)), (5,)), 'adam', 10, 0.01, 5, 97.5, 65.0, 75.0]\n",
      "[(((4, 5, 1), (5, 3, 1)), (5,)), 'adam', 10, 0.1, 5, 97.5, 70.0, 70.0]\n",
      "[(((4, 5, 1), (5, 3, 1)), (5,)), 'adam', 20, 0.01, 5, 100.0, 70.0, 70.0]\n",
      "[(((4, 5, 1), (5, 3, 1)), (5,)), 'adam', 20, 0.1, 5, 100.0, 70.0, 75.0]\n",
      "\n",
      "===========================================================================================\n",
      "Testing\n",
      "\n",
      "    np.random.seed(4200)\n",
      "\n",
      "    n_each_class = 40\n",
      "    X, T = make_images(n_each_class * 2)\n",
      "\n",
      "    structs = [ [[], []],\n",
      "                [[], [10]],\n",
      "                [[[4, 5, 1], [5, 3, 1]], [5]]\n",
      "               ]\n",
      "    methods= ['adam']\n",
      "    n_epochs = [10]\n",
      "    learning_rates = [0.01, 0.1]\n",
      "    batch_sizes = [-1, 5]  # -1 means train on all training samples, not multiple batches\n",
      "    n_folds = 3\n",
      "    \n",
      "    print('This may take several minutes...')\n",
      "    \n",
      "    df = run_these_parameters(X, T, n_folds,\n",
      "                              structs, methods, n_epochs, learning_rates, batch_sizes)\n",
      "\n",
      "    # Here is a function you can use to print all columns and rows of a DataFrame\n",
      "    def print_df(df):\n",
      "        with pandas.option_context('display.width', 100,\n",
      "                                   'display.max_rows', None,\n",
      "                                   'display.max_columns', None):\n",
      "            print(df)\n",
      "\n",
      "This may take several minutes...\n",
      "\n",
      "-- 10 / 10 points. DataFrame returns has correct shape, (72, 8)\n",
      "\n",
      "--- 20 / 20 points. Returned DataFrame has correct percent means of [95.24954212 75.99206349 76.32974664] :\n",
      "\n",
      "============================================================\n",
      "HW Execution Grade is 70 / 70\n",
      "============================================================\n",
      "\n",
      "\n",
      "__ / 5 points.  Discuss what you observe after each call to run_these_parameters with\n",
      "         at least two sentences for each run.\n",
      "\n",
      "__ / 5 points.  Discuss which parameter values seem to work the best according to\n",
      "         the validation accuracy.\n",
      "\n",
      "__ / 5 points.  Discuss how well the validation and test accuracies equal each other\n",
      "          and what you might do to make them more equal.\n",
      "\n",
      "__ / 5 points.  Show and discuss a confusion matrix on test data for a network trained\n",
      "          with your best parameter values.\n",
      "\n",
      "__ / 10 points.  For each method, try various hidden layer structures, learning rates,\n",
      "          and numbers of epochs. Use the validation percent accuracy to pick the best\n",
      "          hidden layers, learning rates and numbers of epochs for each method. Report\n",
      "          training, validation and test accuracy for your best validation results\n",
      "          for each of the three methods.\n",
      "\n",
      "\n",
      "======================================================================\n",
      "HW Results and Discussion Grade is ___ / 30\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "HW FINAL GRADE is  _  / 100\n",
      "======================================================================\n",
      "\n",
      "Extra Credit: \n",
      "Repeat the above experiment using a convolutional neural network defined in Pytorch.\n",
      "Implement this yourself by directly calling torch.nn functions.\n",
      "\n",
      "\n",
      " HW EXTRA CREDIT is 0 / 1\n"
     ]
    }
   ],
   "source": [
    "%run -i A4grader.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Credit\n",
    "\n",
    "Repeat the above experiment using a convolutional neural network defined in `Pytorch`.  Implement this yourself by directly calling `torch.nn` functions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
